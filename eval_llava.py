import argparse
import torch
import os
import json
from tqdm import tqdm
import numpy as np
from torch.utils.data import DataLoader
from sklearn.metrics import average_precision_score, roc_auc_score
from collections import defaultdict

# LLaVA ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN
from llava.conversation import conv_templates, SeparatorStyle
from llava.model.builder import load_pretrained_model
from llava.utils import disable_torch_init
from llava.mm_utils import tokenizer_image_token, get_model_name_from_path, KeywordsStoppingCriteria

# ê¸°ì¡´ ë°ì´í„° ë¡œë” (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ê²½ë¡œ í™•ì¸ í•„ìš”)
import sys
sys.path.append(os.getcwd()) # í˜„ì¬ ê²½ë¡œ ì¶”ê°€
from dataset import make_dataloader

def parse_args():
    parser = argparse.ArgumentParser(description="LLaVA Anomaly Detection Evaluation")
    parser.add_argument("--model_path", type=str, required=True, help="Path to the LoRA checkpoint or merged model")
    parser.add_argument("--model_base", type=str, default="liuhaotian/llava-v1.5-7b", help="Base model (required for LoRA)")
    parser.add_argument("--visa_root", type=str, required=True, help="Path to ViSA dataset root")
    parser.add_argument("--conv_mode", type=str, default="llava_v1")
    parser.add_argument("--batch_size", type=int, default=1)
    parser.add_argument("--image_aspect_ratio", type=str, default="pad")
    parser.add_argument("--output_dir", type=str, default="./eval_results")
    return parser.parse_args()

def get_loss(model, input_ids, attention_mask, images, labels):
    """
    íŠ¹ì • í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤(ì§ˆë¬¸+ì •ë‹µ)ì— ëŒ€í•œ ëª¨ë¸ì˜ Lossë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    with torch.no_grad():
        outputs = model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            images=images,
            labels=labels
        )
    return outputs.loss.item()

# def prepare_input(tokenizer, model, image, meta, label, target_type, conv_mode):
#     """
#     í•™ìŠµ ë°ì´í„°(JSON)ì™€ ë™ì¼í•œ í”„ë¡¬í”„íŠ¸ í˜•ì‹ì„ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •í•¨
#     target_type: 'normal' ë˜ëŠ” 'anomalous'
#     """
    
#     # 1. í•™ìŠµ ë•Œ ì“´ ì§ˆë¬¸ (JSONì˜ "from": "human" ë¶€ë¶„ê³¼ ì¼ì¹˜ì‹œí‚´)
#     # ì£¼ì˜: JSONì—ëŠ” <image>\n ì´ ì•ì— ìˆì§€ë§Œ, LLaVA í…œí”Œë¦¿ ì²˜ë¦¬ ì‹œ ìë™ ì¶”ê°€ë˜ë¯€ë¡œ í…ìŠ¤íŠ¸ë§Œ ì ìŒ
#     qs = "Inspect this image for manufacturing defects. Is this object normal or anomalous? If anomalous, describe the defects."
    
#     # ì´ë¯¸ì§€ í† í° ì¶”ê°€ (LLaVA ì»¨ë²¤ì…˜)
#     if DEFAULT_IMAGE_TOKEN not in qs:
#         qs = DEFAULT_IMAGE_TOKEN + "\n" + qs

#     # 2. ëŒ€í™” í…œí”Œë¦¿ ìƒì„±
#     conv = conv_templates[conv_mode].copy()
#     conv.append_message(conv.roles[0], qs)
    
#     # 3. í›„ë³´ ì •ë‹µ ìƒì„± (JSONì˜ "from": "gpt" ë¶€ë¶„ ìŠ¤íƒ€ì¼ì„ ë”°ë¦„)
#     # í‰ê°€ ì‹œì—ëŠ” êµ¬ì²´ì ì¸ ê²°í•¨ ë‚´ìš©(scratches ë“±)ì„ ëª¨ë¥´ë¯€ë¡œ,
#     # ëª¨ë¸ì´ "The object is normal." vs "The object is anomalous." ì¤‘ ë¬´ì—‡ì„ ë” ì„ í˜¸í•˜ëŠ”ì§€ ë¹„êµí•©ë‹ˆë‹¤.
#     if target_type == 'normal':
#         target_response = "The object is normal."
#     else:
#         # í•™ìŠµ ë°ì´í„°ê°€ "The object is anomalous. Detected defects: ..." í˜•ì‹ì´ì§€ë§Œ,
#         # ì•ë¶€ë¶„ë§Œ ë¹„êµí•´ë„ ì¶©ë¶„í•©ë‹ˆë‹¤. (PerplexityëŠ” ì•ë¶€ë¶„ì´ ë§ìœ¼ë©´ ë‚®ê²Œ ë‚˜ì˜´)
#         target_response = "The object is anomalous."

#     conv.append_message(conv.roles[1], target_response)
#     prompt = conv.get_prompt()

#     # 4. í† í¬ë‚˜ì´ì§•
#     input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).to(model.device)
    
#     # 5. Loss ê³„ì‚°ìš© íƒ€ê²Ÿ ë³µì‚¬
#     targets = input_ids.clone()
    
#     # (ì˜µì…˜) ì§ˆë¬¸ ë¶€ë¶„ ë§ˆìŠ¤í‚¹ì€ ë³µì¡í•˜ë¯€ë¡œ ì¼ë‹¨ ì „ì²´ ë¬¸ì¥ Loss ë¹„êµë¡œ ì§„í–‰
#     # ì •í™•ë„ë¥¼ ë†’ì´ë ¤ë©´ conv.sep ë“±ì„ ì´ìš©í•´ ì§ˆë¬¸ ë¶€ë¶„ì„ -100ìœ¼ë¡œ ì±„ìš°ëŠ” ê²Œ ì¢‹ìŒ
    
#     return input_ids, targets

def prepare_input(tokenizer, model, image, meta, label, target_type, conv_mode):
    """
    [ìˆ˜ì •ë¨] ì§ˆë¬¸(Prompt) ë¶€ë¶„ì„ -100ìœ¼ë¡œ ë§ˆìŠ¤í‚¹í•˜ì—¬ ë‹µë³€(Response)ì˜ Lossë§Œ ê³„ì‚°í•˜ë„ë¡ í•¨
    """
    # 1. ì§ˆë¬¸ ìƒì„±
    qs = "Inspect this image for manufacturing defects. Is this object normal or anomalous? If anomalous, describe the defects."
    if DEFAULT_IMAGE_TOKEN not in qs:
        qs = DEFAULT_IMAGE_TOKEN + "\n" + qs

    # 2. ë‹µë³€ ìƒì„±
    if target_type == 'normal':
        target_response = "The object is normal."
    else:
        target_response = "The object is anomalous."

    # 3. ì „ì²´ ëŒ€í™”(ì§ˆë¬¸+ë‹µë³€) ìƒì„±
    conv = conv_templates[conv_mode].copy()
    conv.append_message(conv.roles[0], qs)
    conv.append_message(conv.roles[1], target_response)
    prompt_full = conv.get_prompt()

    # 4. ì§ˆë¬¸ ë¶€ë¶„ë§Œ ë”°ë¡œ ìƒì„± (ê¸¸ì´ ì¸¡ì •ìš©)
    conv = conv_templates[conv_mode].copy()
    conv.append_message(conv.roles[0], qs)
    conv.append_message(conv.roles[1], None)
    prompt_q = conv.get_prompt()

    # 5. í† í¬ë‚˜ì´ì§•
    input_ids = tokenizer_image_token(prompt_full, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).to(model.device)
    
    # ì§ˆë¬¸ ê¸¸ì´ ê³„ì‚° (ë‹µë³€ì´ ì‹œì‘ë˜ëŠ” ìœ„ì¹˜ ì°¾ê¸°)
    # ì£¼ì˜: tokenizer ì„¤ì •ì— ë”°ë¼ í† í°í™” ë°©ì‹ì´ ë‹¤ë¥¼ ìˆ˜ ìˆì–´, ì§ì ‘ ë‘ ë²ˆ í† í¬ë‚˜ì´ì§•í•´ì„œ ë¹„êµí•©ë‹ˆë‹¤.
    tokenized_q = tokenizer_image_token(prompt_q, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt')
    len_q = tokenized_q.shape[0]

    # 6. Loss ê³„ì‚°ìš© íƒ€ê²Ÿ ìƒì„± ë° ë§ˆìŠ¤í‚¹
    targets = input_ids.clone()
    # ì§ˆë¬¸ êµ¬ê°„(0 ~ len_q)ì€ -100ìœ¼ë¡œ ì±„ì›Œì„œ Loss ê³„ì‚° ì œì™¸ (Ignore Index)
    targets[0, :len_q] = -100 

    return input_ids, targets

def main():
    args = parse_args()
    disable_torch_init()
    
    # 1. ëª¨ë¸ ë¡œë“œ (LoRA ì–´ëŒ‘í„° í¬í•¨)
    model_name = get_model_name_from_path(args.model_path)
    tokenizer, model, image_processor, context_len = load_pretrained_model(
        args.model_path, 
        args.model_base, 
        model_name, 
        load_4bit=True  # í•™ìŠµ ì‹œ 4bitë¥¼ ì¼ìœ¼ë¯€ë¡œ í‰ê°€ë„ 4bit ê¶Œì¥ (ë©”ëª¨ë¦¬ ì ˆì•½)
    )

    # 2. ë°ì´í„° ë¡œë” ì¤€ë¹„
    test_loader = make_dataloader(
        root=args.visa_root,
        dataset_name="visa",
        split="test",
        batch_size=args.batch_size, # Loss ë¹„êµ ë°©ì‹ì€ batch 1ì´ ì•ˆì „í•¨
        num_workers=4,
        image_size=336, # LLaVA v1.5 ê¸°ë³¸ í•´ìƒë„
        return_mask=False,
        shuffle=False
    )

    # 3. í‰ê°€ ë£¨í”„
    target_normal = "Prediction: normal. Rationale: no visible defects."
    target_anom = "Prediction: anomalous. Rationale: visible defect patterns present."

    gts = []
    preds = []
    anomaly_print_count = 0
    normal_print_count = 0
    target_count = 100
    normal_diffs = []    # ì •ìƒ ì´ë¯¸ì§€ë“¤ì˜ (Loss_Anom - Loss_Norm) ê°’
    anomaly_diffs = []   # ë¶ˆëŸ‰ ì´ë¯¸ì§€ë“¤ì˜ (Loss_Anom - Loss_Norm) ê°’
    category_results = defaultdict(list)
    
    os.makedirs(args.output_dir, exist_ok=True)

    print("Start Evaluation...")
    for batch in tqdm(test_loader):
        # ë°°ì¹˜ ì‚¬ì´ì¦ˆê°€ 1ì´ë¼ê³  ê°€ì •
        image_tensor = batch["image"].to(model.device, dtype=torch.float16)
        # image_tensor_flipped = torch.flip(image_tensor, [3])
        label = int(batch["label"].item())
        meta = batch["meta"] # list of dict, but batch=1 -> dict ì ‘ê·¼ í•„ìš”
        if isinstance(meta, list): meta = meta[0]
        # if label == 0 and normal_print_count > 50:
        #     continue
        # if label == 1 and anomaly_print_count > 50:
        #     continue
        # LLaVA Image Processor ì ìš© (ì´ë¯¸ DataLoaderì—ì„œ ì „ì²˜ë¦¬ ë˜ì—ˆì„ ìˆ˜ ìˆìŒ í™•ì¸ í•„ìš”)
        # make_dataloaderê°€ CLIP transformì„ ì“´ë‹¤ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, raw imageë¼ë©´ image_processor.preprocess í•„ìš”.
        # ì—¬ê¸°ì„œëŠ” DataLoaderê°€ í…ì„œë¥¼ ì¤€ë‹¤ê³  ê°€ì •í•˜ê³  ê·¸ëŒ€ë¡œ ì‚¬ìš©. 
        # ë§Œì•½ CLIP ViT ì…ë ¥ì„ ìœ„í•´ ì¶”ê°€ ì²˜ë¦¬ê°€ í•„ìš”í•˜ë‹¤ë©´ image_processor ì‚¬ìš©.
        
        # 4. Normal ê°€ì„¤ ê²€ì¦
        input_ids_n, targets_n = prepare_input(tokenizer, model, image_tensor, meta, label, 'normal', args.conv_mode)
        loss_normal = get_loss(model, input_ids_n, None, image_tensor, targets_n)

        # 5. Anomaly ê°€ì„¤ ê²€ì¦ ("The object is anomalous.")
        input_ids_a, targets_a = prepare_input(tokenizer, model, image_tensor, meta, label, 'anomalous', args.conv_mode)
        loss_anom = get_loss(model, input_ids_a, None, image_tensor, targets_a)

        # # ---------------------------------------------------------
        # # [2] ë’¤ì§‘ì€ ì´ë¯¸ì§€ í‰ê°€ (ê²€ì¦ìš©)
        # # ---------------------------------------------------------
        # # ê°™ì€ ì§ˆë¬¸ìœ¼ë¡œ ë’¤ì§‘ì€ ì´ë¯¸ì§€ë„ ë„£ì–´ë´…ë‹ˆë‹¤.
        # loss_normal_flip = get_loss(model, input_ids_n, None, image_tensor_flipped, targets_n)
        # loss_anom_flip = get_loss(model, input_ids_a, None, image_tensor_flipped, targets_a)

        # # ---------------------------------------------------------
        # # [3] ì ìˆ˜ í•©ì‚° (ì•™ìƒë¸”)
        # # ---------------------------------------------------------
        # # ì›ë³¸ê³¼ ë°˜ì „ ì´ë¯¸ì§€ì˜ Lossë¥¼ í‰ê·  ëƒ…ë‹ˆë‹¤. (ë…¸ì´ì¦ˆê°€ ì¤„ì–´ë“­ë‹ˆë‹¤!)
        # loss_normal = (loss_normal + loss_normal_flip) / 2
        # loss_anom = (loss_anom + loss_anom_flip) / 2


        # 6. ì˜ˆì¸¡ (Lossê°€ ë‚®ì€ ìª½ ì„ íƒ)
        pred = 0 if loss_normal < loss_anom else 1
        diff = loss_anom - loss_normal
        
        anomaly_score = loss_normal - loss_anom 
        
        # 3. ê²°ê³¼ ìˆ˜ì§‘ (ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì €ì¥)
        category = meta.get('category', 'unknown')
        category_results[category].append((label, anomaly_score))
        
        # ============ [ë””ë²„ê¹… ì½”ë“œ ì‹œì‘] ============
        # ì‹¤ì œ ì •ë‹µì´ 'ë¶ˆëŸ‰(1)'ì¸ë°, ëª¨ë¸ì´ í—·ê°ˆë ¤í•˜ëŠ”ì§€ í™•ì¸
        
        if label == 0:  # ë”± 10ê°œë§Œ ì°ì–´ë´…ë‹ˆë‹¤.
            print(f"\n======== [Anomaly Case Check #{normal_print_count+1}] ========")
            print(f"ğŸ“¸ Image Meta: {meta}")
            print(f"ğŸ“‰ Loss (Normal Sentence): {loss_normal:.4f}")
            print(f"ğŸ“‰ Loss (Anomaly Sentence): {loss_anom:.4f}")
            
            if diff > 0:
                print(f"âœ… ê²°ê³¼: ì„±ê³µ! (ì •ìƒ ë¬¸ì¥ì˜ Lossê°€ {abs(diff):.4f}ë§Œí¼ ë” ë‚®ìŒ)")
            else:
                print(f"âŒ ê²°ê³¼: ì‹¤íŒ¨... (ë¶ˆëŸ‰ ë¬¸ì¥ì„ ë” ì„ í˜¸í•¨, ì°¨ì´: {diff:.4f})")
            
            print(f"ğŸ¤– ëª¨ë¸ ì˜ˆì¸¡: {'Anomalous' if pred==1 else 'Normal'} (ì •ë‹µ: Normal)")
            print("========================================================\n")
            normal_print_count += 1        
            normal_diffs.append(diff)
        
        if label == 1:  # ë”± 10ê°œë§Œ ì°ì–´ë´…ë‹ˆë‹¤.
            print(f"\n======== [Anomaly Case Check #{anomaly_print_count+1}] ========")
            print(f"ğŸ“¸ Image Meta: {meta}")
            print(f"ğŸ“‰ Loss (Normal Sentence): {loss_normal:.4f}")
            print(f"ğŸ“‰ Loss (Anomaly Sentence): {loss_anom:.4f}")
            
            if diff < 0:
                print(f"âœ… ê²°ê³¼: ì„±ê³µ! (ë¶ˆëŸ‰ ë¬¸ì¥ì˜ Lossê°€ {abs(diff):.4f}ë§Œí¼ ë” ë‚®ìŒ)")
            else:
                print(f"âŒ ê²°ê³¼: ì‹¤íŒ¨... (ì •ìƒ ë¬¸ì¥ì„ ë” ì„ í˜¸í•¨, ì°¨ì´: {diff:.4f})")
            
            print(f"ğŸ¤– ëª¨ë¸ ì˜ˆì¸¡: {'Anomalous' if pred==1 else 'Normal'} (ì •ë‹µ: Anomalous)")
            print("========================================================\n")
            anomaly_print_count += 1
            anomaly_diffs.append(diff)
        # ============ [ë””ë²„ê¹… ì½”ë“œ ë] ============
        
        gts.append(label)
        preds.append(pred)

    # 7. ë©”íŠ¸ë¦­ ê³„ì‚°
    gts = np.array(gts)
    preds = np.array(preds)

    tp = int(((preds==1)&(gts==1)).sum())
    fp = int(((preds==1)&(gts==0)).sum())
    tn = int(((preds==0)&(gts==0)).sum())
    fn = int(((preds==0)&(gts==1)).sum())

    precision = tp / max(1, (tp + fp))
    recall = tp / max(1, (tp + fn))
    f1 = 2 * precision * recall / max(1e-8, (precision + recall))
    acc = (tp + tn) / len(gts)

    print(f"Total: {len(gts)}")
    print(f"Accuracy: {acc:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1:.4f}")

    # ê²°ê³¼ ì €ì¥
    with open(os.path.join(args.output_dir, "results.txt"), "w") as f:
        f.write(f"Accuracy: {acc:.4f}\n")
        f.write(f"Precision: {precision:.4f}\n")
        f.write(f"Recall: {recall:.4f}\n")
        f.write(f"F1 Score: {f1:.4f}\n")
        f.write(f"TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}\n")
    
    norm_arr = np.array(normal_diffs)
    anom_arr = np.array(anomaly_diffs)

    print("\n======== [Calibration Result] ========")
    print(f"ğŸŸ¢ Normal Case Diffs (Mean): {norm_arr.mean():.4f} (Std: {norm_arr.std():.4f})")
    print(f"ğŸ”´ Anomaly Case Diffs (Mean): {anom_arr.mean():.4f} (Std: {anom_arr.std():.4f})")
    
    # 0ì„ ê¸°ì¤€ìœ¼ë¡œ í–ˆì„ ë•Œì˜ ì •í™•ë„
    # (ì›ë˜ ë¡œì§: diff > 0 ì´ë©´ Normal ì˜ˆì¸¡)
    acc_naive_norm = (norm_arr > 0).sum() / len(norm_arr) if len(norm_arr) > 0 else 0
    acc_naive_anom = (anom_arr <= 0).sum() / len(anom_arr) if len(anom_arr) > 0 else 0
    print(f"ğŸ“‰ ê¸°ì¤€ì  0.0 ì¼ ë•Œ Accuracy -> Normal: {acc_naive_norm*100:.1f}%, Anomaly: {acc_naive_anom*100:.1f}%")

    # ğŸ’¡ ìµœì  Threshold ì°¾ê¸° (ê°„ë‹¨í•œ ë²„ì „: ë‘ í‰ê· ì˜ ì¤‘ê°„ê°’)
    # ì •êµí•˜ê²Œ í•˜ë ¤ë©´ ROC Curveë¥¼ ê·¸ë ¤ì„œ Youden Indexë¥¼ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ë‘ ë¶„í¬ê°€ ê²¹ì¹˜ëŠ” êµ¬ê°„ì„ ë´…ë‹ˆë‹¤.
    
    if len(norm_arr) > 0 and len(anom_arr) > 0:
        # ëª¨ë¸ì´ í¸í–¥ë˜ì–´ì„œ Normal í‰ê· ì´ ìŒìˆ˜(-0.5)ë¼ë©´, ê¸°ì¤€ì ì„ -0.5 ê·¼ì²˜ë¡œ ì˜®ê²¨ì•¼ í•©ë‹ˆë‹¤.
        optimal_threshold = (norm_arr.mean() + anom_arr.mean()) / 2
        print(f"âš–ï¸ ì¶”ì²œ ìµœì  Threshold: {optimal_threshold:.4f}")
        
        # ë³´ì •ëœ Thresholdë¡œ ë‹¤ì‹œ ê³„ì‚°
        acc_calib_norm = (norm_arr > optimal_threshold).sum() / len(norm_arr)
        acc_calib_anom = (anom_arr <= optimal_threshold).sum() / len(anom_arr)
        print(f"ğŸ“ˆ ë³´ì • í›„ ì˜ˆìƒ Accuracy -> Normal: {acc_calib_norm*100:.1f}%, Anomaly: {acc_calib_anom*100:.1f}%")
        
        # F1 Score ì¬ê³„ì‚° (TP, FP, TN, FN)
        # Thresholdë³´ë‹¤ í¬ë©´ Normal(0), ì‘ìœ¼ë©´ Anomaly(1)
        TP = (anom_arr <= optimal_threshold).sum()
        FN = (anom_arr > optimal_threshold).sum()
        TN = (norm_arr > optimal_threshold).sum()
        FP = (norm_arr <= optimal_threshold).sum()
        
        precision = TP / (TP + FP + 1e-8)
        recall = TP / (TP + FN + 1e-8)
        f1 = 2 * precision * recall / (precision + recall + 1e-8)
        
        print(f"ğŸ† Final Calibrated F1 Score: {f1:.4f}")
    else:
        print("ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ Thresholdë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    print("\n" + "="*40)
    print(f"{'Category':<15} | {'AP':<10} | {'AUROC':<10}")
    print("-" * 40)
    
    ap_list = []
    auroc_list = []
    
    for cat, data in category_results.items():
        # ë°ì´í„° ë¶„ë¦¬
        y_true = [x[0] for x in data]      # ì •ë‹µ (0:ì •ìƒ, 1:ë¶ˆëŸ‰)
        y_scores = [x[1] for x in data]    # ì˜ˆì¸¡ ì ìˆ˜
        
        # ë°ì´í„°ê°€ ì„ì—¬ ìˆì–´ì•¼(ì •ìƒ/ë¶ˆëŸ‰ ë‘˜ ë‹¤ ì¡´ì¬) ê³„ì‚° ê°€ëŠ¥
        if len(set(y_true)) < 2:
            print(f"{cat:<15} | {'N/A':<10} | {'N/A':<10} (Only one class present)")
            continue
            
        # AP (Average Precision) ê³„ì‚°
        ap = average_precision_score(y_true, y_scores)
        
        # AUROC (Area Under ROC) ê³„ì‚° - ë¤ìœ¼ë¡œ ê°™ì´ ë´…ë‹ˆë‹¤
        auroc = roc_auc_score(y_true, y_scores)
        
        ap_list.append(ap)
        auroc_list.append(auroc)
        
        print(f"{cat:<15} | {ap:.4f}     | {auroc:.4f}")

    print("-" * 40)
    
    # mAP (APë“¤ì˜ í‰ê· )
    if len(ap_list) > 0:
        mAP = sum(ap_list) / len(ap_list)
        mAUROC = sum(auroc_list) / len(auroc_list)
        print(f"ğŸ¥‡ mAP (Mean Average Precision): {mAP:.4f}")
        print(f"ğŸ¥ˆ mAUROC (Mean AUROC)       : {mAUROC:.4f}")
        
        # íŒŒì¼ ì €ì¥
        with open(os.path.join(args.output_dir, "map_results.txt"), "w") as f:
            f.write(f"mAP: {mAP:.4f}\n")
            f.write(f"mAUROC: {mAUROC:.4f}\n")
    else:
        print("ê³„ì‚° ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

    print("\n======== [Finding Optimal F1 Score] ========")
    from sklearn.metrics import precision_recall_curve

    all_labels = []
    all_scores = []

    # ëª¨ë“  ì¹´í…Œê³ ë¦¬ì˜ ë°ì´í„°ë¥¼ í•œê³³ì— ëª¨ìë‹ˆë‹¤.
    for cat, data in category_results.items():
        for label, score in data:
            all_labels.append(label)
            all_scores.append(score)

    all_labels = np.array(all_labels)
    all_scores = np.array(all_scores)

    # Precision-Recall Curveë¥¼ ê·¸ë ¤ì„œ ìµœê³ ì˜ F1 ì§€ì ì„ ì°¾ìŠµë‹ˆë‹¤.
    precision, recall, thresholds = precision_recall_curve(all_labels, all_scores)
    
    # F1 ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
    numerator = 2 * precision * recall
    denominator = precision + recall
    f1_scores = np.divide(numerator, denominator, out=np.zeros_like(numerator), where=denominator != 0)
    
    # ìµœëŒ€ F1 Scoreì™€ ê·¸ë•Œì˜ Threshold ì°¾ê¸°
    best_idx = np.argmax(f1_scores)
    best_f1 = f1_scores[best_idx]
    best_threshold = thresholds[best_idx]

    print(f"ğŸ’ Best Possible F1 Score: {best_f1:.4f}")
    print(f"âš–ï¸ Optimal Threshold: {best_threshold:.4f}")
    print("--------------------------------------------")
    print("ì´ ê°’ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì˜ˆì¸¡ì„ í•˜ë©´ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤.")

    print("\n" + "="*50)
    print("ğŸ’ Calculating Best F1 Score per Category")
    print("="*50)
    
    f1_list = []
    
    print(f"{'Category':<15} | {'Best F1':<10} | {'Threshold':<10}")
    print("-" * 50)

    # 1. ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë”°ë¡œë”°ë¡œ ìµœì ì˜ F1ì„ êµ¬í•©ë‹ˆë‹¤.
    for cat, data in category_results.items():
        y_true = np.array([x[0] for x in data])
        y_scores = np.array([x[1] for x in data])

        # ì •ìƒ ë˜ëŠ” ë¶ˆëŸ‰ ë°ì´í„°ë§Œ ìˆëŠ” ê²½ìš° ê³„ì‚° ë¶ˆê°€
        if len(set(y_true)) < 2:
            print(f"{cat:<15} | {'N/A':<10} | {'N/A':<10} (Skipped)")
            continue

        # Precision-Recall Curve ê³„ì‚°
        precision, recall, thresholds = precision_recall_curve(y_true, y_scores)
        
        # F1 Score ê³„ì‚°
        numerator = 2 * precision * recall
        denominator = precision + recall
        f1_scores = np.divide(numerator, denominator, out=np.zeros_like(numerator), where=denominator != 0)
        
        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œì˜ ìµœê³  ì ìˆ˜ ì°¾ê¸°
        best_idx = np.argmax(f1_scores)
        best_f1 = f1_scores[best_idx]
        best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else thresholds[-1]
        
        f1_list.append(best_f1)
        
        print(f"{cat:<15} | {best_f1:.4f}     | {best_threshold:.4f}")

    print("-" * 50)

    # 2. ìµœì¢… ì ìˆ˜: ì¹´í…Œê³ ë¦¬ë³„ F1ì˜ í‰ê·  (Macro Average)
    if len(f1_list) > 0:
        macro_f1 = sum(f1_list) / len(f1_list)
        print(f"ğŸ† Class-Average Best F1 Score: {macro_f1:.4f}")
        
        with open(os.path.join(args.output_dir, "class_wise_f1.txt"), "w") as f:
            f.write(f"Class-Average Best F1: {macro_f1:.4f}\n")
    else:
        print("ê³„ì‚°ëœ F1 ì ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()