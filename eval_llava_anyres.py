import argparse
import torch
import os
from PIL import Image
import json
from tqdm import tqdm
import numpy as np
from torch.utils.data import DataLoader
from sklearn.metrics import average_precision_score, roc_auc_score
from collections import defaultdict

# LLaVA ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN
from llava.conversation import conv_templates, SeparatorStyle
from llava.model.builder import load_pretrained_model
from llava.utils import disable_torch_init
from llava.mm_utils import tokenizer_image_token, get_model_name_from_path, KeywordsStoppingCriteria, process_images
from PIL import Image
from pathlib import Path

# ê¸°ì¡´ ë°ì´í„° ë¡œë” (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ê²½ë¡œ í™•ì¸ í•„ìš”)
import sys
sys.path.append(os.getcwd()) # í˜„ì¬ ê²½ë¡œ ì¶”ê°€
from dataset import make_dataloader

def parse_args():
    parser = argparse.ArgumentParser(description="LLaVA Anomaly Detection Evaluation")
    parser.add_argument("--model_path", type=str, required=True, help="Path to the LoRA checkpoint or merged model")
    parser.add_argument("--model_base", type=str, default="liuhaotian/llava-v1.6-vicuna-7b", help="Base model (required for LoRA)")
    parser.add_argument("--visa_root", type=str, required=True, help="Path to ViSA dataset root")
    parser.add_argument("--conv_mode", type=str, default="llava_v1")
    parser.add_argument("--batch_size", type=int, default=1)
    parser.add_argument("--image_aspect_ratio", type=str, default="pad")
    parser.add_argument("--mm_patch_merge_type", type=str, default=None)  # optional override
    parser.add_argument("--image_grid_pinpoints", type=str, default=None,
                    help="Only needed if model config lacks image_grid_pinpoints. "
                         "Pass same value used in training/config.json.")
    parser.add_argument("--output_dir", type=str, default="./eval_results")
    return parser.parse_args()

def get_loss(model, input_ids, attention_mask, images, labels, image_sizes=None):
    """
    íŠ¹ì • í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤(ì§ˆë¬¸+ì •ë‹µ)ì— ëŒ€í•œ ëª¨ë¸ì˜ Lossë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    with torch.no_grad():
        outputs = model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            images=images,
            labels=labels,
            image_sizes=image_sizes,  
        )
    return outputs.loss.item()

def prepare_input(tokenizer, model, image, meta, label, target_type, conv_mode):
    """
    [ìˆ˜ì •ë¨] ì§ˆë¬¸(Prompt) ë¶€ë¶„ì„ -100ìœ¼ë¡œ ë§ˆìŠ¤í‚¹í•˜ì—¬ ë‹µë³€(Response)ì˜ Lossë§Œ ê³„ì‚°í•˜ë„ë¡ í•¨
    """
    # 1. ì§ˆë¬¸ ìƒì„±
    qs = "Inspect this image for manufacturing defects. Is this object normal or anomalous? If anomalous, describe the defects."
    if DEFAULT_IMAGE_TOKEN not in qs:
        qs = DEFAULT_IMAGE_TOKEN + "\n" + qs

    # 2. ë‹µë³€ ìƒì„±
    if target_type == 'normal':
        target_response = "The object is normal."
    else:
        target_response = "The object is anomalous."

    # 3. ì „ì²´ ëŒ€í™”(ì§ˆë¬¸+ë‹µë³€) ìƒì„±
    conv = conv_templates[conv_mode].copy()
    conv.append_message(conv.roles[0], qs)
    conv.append_message(conv.roles[1], target_response)
    prompt_full = conv.get_prompt()

    # 4. ì§ˆë¬¸ ë¶€ë¶„ë§Œ ë”°ë¡œ ìƒì„± (ê¸¸ì´ ì¸¡ì •ìš©)
    conv = conv_templates[conv_mode].copy()
    conv.append_message(conv.roles[0], qs)
    conv.append_message(conv.roles[1], None)
    prompt_q = conv.get_prompt()

    # 5. í† í¬ë‚˜ì´ì§•
    input_ids = tokenizer_image_token(prompt_full, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).to(model.device)
    
    # ì§ˆë¬¸ ê¸¸ì´ ê³„ì‚° (ë‹µë³€ì´ ì‹œì‘ë˜ëŠ” ìœ„ì¹˜ ì°¾ê¸°)
    # ì£¼ì˜: tokenizer ì„¤ì •ì— ë”°ë¼ í† í°í™” ë°©ì‹ì´ ë‹¤ë¥¼ ìˆ˜ ìˆì–´, ì§ì ‘ ë‘ ë²ˆ í† í¬ë‚˜ì´ì§•í•´ì„œ ë¹„êµí•©ë‹ˆë‹¤.
    tokenized_q = tokenizer_image_token(prompt_q, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt')
    len_q = tokenized_q.shape[0]

    # 6. Loss ê³„ì‚°ìš© íƒ€ê²Ÿ ìƒì„± ë° ë§ˆìŠ¤í‚¹
    targets = input_ids.clone()
    # ì§ˆë¬¸ êµ¬ê°„(0 ~ len_q)ì€ -100ìœ¼ë¡œ ì±„ì›Œì„œ Loss ê³„ì‚° ì œì™¸ (Ignore Index)
    targets[0, :len_q] = -100 

    return input_ids, targets

def main():
    args = parse_args()
    disable_torch_init()
    
    # 1. ëª¨ë¸ ë¡œë“œ (LoRA ì–´ëŒ‘í„° í¬í•¨)
    model_name = get_model_name_from_path(args.model_path)
    tokenizer, model, image_processor, context_len = load_pretrained_model(
        args.model_path, 
        args.model_base, 
        model_name, 
        device_map=None,
        device="cuda",
        load_4bit=False  # í•™ìŠµ ì‹œ 4bitë¥¼ ì¼ìœ¼ë¯€ë¡œ í‰ê°€ë„ 4bit ê¶Œì¥ (ë©”ëª¨ë¦¬ ì ˆì•½)
    )

    from accelerate import infer_auto_device_map, dispatch_model
    import torch

    # GPU ê°œìˆ˜/ë©”ëª¨ë¦¬ ì¡ê¸°
    n_gpus = torch.cuda.device_count()
    assert n_gpus >= 2, "ë©€í‹° GPU ìƒ¤ë”©í•˜ë ¤ë©´ GPUê°€ 2ì¥ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤."

    # GPU0ì—ëŠ” CLIPì´ ì˜¬ë¼ê°ˆ ê±°ë‹ˆê¹Œ LLMìš© ë©”ëª¨ë¦¬ë¥¼ ì¢€ ë¹„ì›Œë‘  (ì˜ˆ: 3~4GB ì—¬ìœ )
    max_memory = {i: "10GiB" for i in range(n_gpus)}     # <- ê° GPU VRAMì— ë§ê²Œ ì¡°ì ˆ
    max_memory[0] = "6GiB"                                # <- GPU0ì€ CLIP ìë¦¬ ë‚¨ê¸°ê¸° (ì¤‘ìš”)

    # LLaMAëŠ” ë ˆì´ì–´ë¥¼ ìª¼ê°œë©´ ì•ˆ ë˜ë¯€ë¡œ no_split ì§€ì •
    device_map = infer_auto_device_map(
        model,
        max_memory=max_memory,
        no_split_module_classes=["LlamaDecoderLayer"],
        dtype=torch.float16,
    )

    model = dispatch_model(model, device_map=device_map)
    print("LLM device_map =", getattr(model, "hf_device_map", None))
    vt = model.get_vision_tower()
    proj = model.get_model().mm_projector.to(vt.device)
    print("vision_tower device:", vt.device, "dtype:", vt.dtype)
    print("mm_projector device:", next(proj.parameters()).device, "dtype:", next(proj.parameters()).dtype)
    # transformers device_map í™•ì¸(ìˆìœ¼ë©´)
    print("hf_device_map:", getattr(model, "hf_device_map", None))

    model.config.image_aspect_ratio = args.image_aspect_ratio
    if args.mm_patch_merge_type is not None:
        model.config.mm_patch_merge_type = args.mm_patch_merge_type

    if args.image_aspect_ratio == "anyres":
        # process_images(anyres)ê°€ ì´ ê°’ì„ ì”ë‹ˆë‹¤.
        if not hasattr(model.config, "image_grid_pinpoints") or model.config.image_grid_pinpoints is None:
            if args.image_grid_pinpoints is None:
                raise ValueError("anyres requires model.config.image_grid_pinpoints. "
                                "Pass --image_grid_pinpoints or ensure it's in config.json.")
            model.config.image_grid_pinpoints = args.image_grid_pinpoints

    
    # 2. ë°ì´í„° ë¡œë” ì¤€ë¹„
    test_loader = make_dataloader(
        root=args.visa_root,
        dataset_name="visa",
        split="test",
        batch_size=args.batch_size, # Loss ë¹„êµ ë°©ì‹ì€ batch 1ì´ ì•ˆì „í•¨
        num_workers=4,
        image_size=336, # LLaVA v1.5 ê¸°ë³¸ í•´ìƒë„
        return_mask=False,
        shuffle=False
    )

    # 3. í‰ê°€ ë£¨í”„
    target_normal = "Prediction: normal. Rationale: no visible defects."
    target_anom = "Prediction: anomalous. Rationale: visible defect patterns present."

    gts = []
    preds = []
    anomaly_print_count = 0
    normal_print_count = 0
    target_count = 100
    normal_diffs = []    # ì •ìƒ ì´ë¯¸ì§€ë“¤ì˜ (Loss_Anom - Loss_Norm) ê°’
    anomaly_diffs = []   # ë¶ˆëŸ‰ ì´ë¯¸ì§€ë“¤ì˜ (Loss_Anom - Loss_Norm) ê°’
    category_results = defaultdict(list)
    
    os.makedirs(args.output_dir, exist_ok=True)

    print("Start Evaluation...")
    def resolve_image_path(meta, visa_root):
        # metaì— ë“¤ì–´ìˆëŠ” ê²½ë¡œ í‚¤ëŠ” êµ¬í˜„ë§ˆë‹¤ ë‹¬ë¼ì„œ ì—¬ëŸ¬ í›„ë³´ë¥¼ ìˆœì„œëŒ€ë¡œ ë´…ë‹ˆë‹¤.
        for k in ["img_path", "image_path", "path", "file_path", "filepath", "file_name", "filename", "image"]:
            if k in meta and meta[k]:
                p = str(meta[k])
                if os.path.isabs(p):
                    return p
                return str(Path(visa_root) / p)
        raise KeyError(f"Cannot find image path in meta keys={list(meta.keys())}")

    for batch in tqdm(test_loader):
        # ë°°ì¹˜ ì‚¬ì´ì¦ˆê°€ 1ì´ë¼ê³  ê°€ì •
        # image_tensor = batch["image"].to(model.device, dtype=torch.float16)
        image_tensor = batch["image"].to(vt.device, dtype=vt.dtype)
        # image_tensor_flipped = torch.flip(image_tensor, [3])
        label = int(batch["label"].item())
        meta = batch["meta"] # list of dict, but batch=1 -> dict ì ‘ê·¼ í•„ìš”
        if isinstance(meta, list): 
            meta = meta[0]

        if args.image_aspect_ratio == "anyres":
            # 1) PIL ì›ë³¸ ë¡œë“œ
            img_path = resolve_image_path(meta, args.visa_root)
            pil_img = Image.open(img_path).convert("RGB")

            # 2) anyres íŒ¨ì¹˜ ì „ì²˜ë¦¬ + ì›ë³¸ ì‚¬ì´ì¦ˆ ê¸°ë¡ (w,h)
            image_sizes = [pil_img.size]  # [(width, height)]
            images = process_images([pil_img], image_processor, model.config)

            # 3) vision_tower ë””ë°”ì´ìŠ¤/íƒ€ì…ìœ¼ë¡œ ì´ë™
            if isinstance(images, torch.Tensor):
                image_tensor = images.to(vt.device, dtype=vt.dtype)
            else:
                # (íŒ¨ì¹˜ ê°œìˆ˜ê°€ ì´ë¯¸ì§€ë§ˆë‹¤ ë‹¤ë¥´ë©´ listë¡œ ì˜¬ ìˆ˜ ìˆìŒ)
                image_tensor = [x.to(vt.device, dtype=vt.dtype) for x in images]
        else:
            image_sizes = None
            image_tensor = batch["image"].to(vt.device, dtype=vt.dtype)
        
        # 4. Normal ê°€ì„¤ ê²€ì¦
        input_ids_n, targets_n = prepare_input(tokenizer, model, image_tensor, meta, label, 'normal', args.conv_mode)
        loss_normal = get_loss(model, input_ids_n, None, image_tensor, targets_n, image_sizes=image_sizes)

        # 5. Anomaly ê°€ì„¤ ê²€ì¦ ("The object is anomalous.")
        input_ids_a, targets_a = prepare_input(tokenizer, model, image_tensor, meta, label, 'anomalous', args.conv_mode)
        loss_anom = get_loss(model, input_ids_a, None, image_tensor, targets_a, image_sizes=image_sizes)
        # # ---------------------------------------------------------
        # # [2] ë’¤ì§‘ì€ ì´ë¯¸ì§€ í‰ê°€ (ê²€ì¦ìš©)
        # # ---------------------------------------------------------
        # # ê°™ì€ ì§ˆë¬¸ìœ¼ë¡œ ë’¤ì§‘ì€ ì´ë¯¸ì§€ë„ ë„£ì–´ë´…ë‹ˆë‹¤.
        # loss_normal_flip = get_loss(model, input_ids_n, None, image_tensor_flipped, targets_n)
        # loss_anom_flip = get_loss(model, input_ids_a, None, image_tensor_flipped, targets_a)

        # # ---------------------------------------------------------
        # # [3] ì ìˆ˜ í•©ì‚° (ì•™ìƒë¸”)
        # # ---------------------------------------------------------
        # # ì›ë³¸ê³¼ ë°˜ì „ ì´ë¯¸ì§€ì˜ Lossë¥¼ í‰ê·  ëƒ…ë‹ˆë‹¤. (ë…¸ì´ì¦ˆê°€ ì¤„ì–´ë“­ë‹ˆë‹¤!)
        # loss_normal = (loss_normal + loss_normal_flip) / 2
        # loss_anom = (loss_anom + loss_anom_flip) / 2


        # 6. ì˜ˆì¸¡ (Lossê°€ ë‚®ì€ ìª½ ì„ íƒ)
        pred = 0 if loss_normal < loss_anom else 1
        diff = loss_anom - loss_normal
        
        anomaly_score = loss_normal - loss_anom 
        
        # 3. ê²°ê³¼ ìˆ˜ì§‘ (ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì €ì¥)
        category = meta.get('category', 'unknown')
        category_results[category].append((label, anomaly_score))
        
        # ============ [ë””ë²„ê¹… ì½”ë“œ ì‹œì‘] ============
        # ì‹¤ì œ ì •ë‹µì´ 'ë¶ˆëŸ‰(1)'ì¸ë°, ëª¨ë¸ì´ í—·ê°ˆë ¤í•˜ëŠ”ì§€ í™•ì¸
        
        if label == 0:  # ë”± 10ê°œë§Œ ì°ì–´ë´…ë‹ˆë‹¤.
            print(f"\n======== [Anomaly Case Check #{normal_print_count+1}] ========")
            print(f"ğŸ“¸ Image Meta: {meta}")
            print(f"ğŸ“‰ Loss (Normal Sentence): {loss_normal:.4f}")
            print(f"ğŸ“‰ Loss (Anomaly Sentence): {loss_anom:.4f}")
            
            if diff > 0:
                print(f"âœ… ê²°ê³¼: ì„±ê³µ! (ì •ìƒ ë¬¸ì¥ì˜ Lossê°€ {abs(diff):.4f}ë§Œí¼ ë” ë‚®ìŒ)")
            else:
                print(f"âŒ ê²°ê³¼: ì‹¤íŒ¨... (ë¶ˆëŸ‰ ë¬¸ì¥ì„ ë” ì„ í˜¸í•¨, ì°¨ì´: {diff:.4f})")
            
            print(f"ğŸ¤– ëª¨ë¸ ì˜ˆì¸¡: {'Anomalous' if pred==1 else 'Normal'} (ì •ë‹µ: Normal)")
            print("========================================================\n")
            normal_print_count += 1        
            normal_diffs.append(diff)
        
        if label == 1:  # ë”± 10ê°œë§Œ ì°ì–´ë´…ë‹ˆë‹¤.
            print(f"\n======== [Anomaly Case Check #{anomaly_print_count+1}] ========")
            print(f"ğŸ“¸ Image Meta: {meta}")
            print(f"ğŸ“‰ Loss (Normal Sentence): {loss_normal:.4f}")
            print(f"ğŸ“‰ Loss (Anomaly Sentence): {loss_anom:.4f}")
            
            if diff < 0:
                print(f"âœ… ê²°ê³¼: ì„±ê³µ! (ë¶ˆëŸ‰ ë¬¸ì¥ì˜ Lossê°€ {abs(diff):.4f}ë§Œí¼ ë” ë‚®ìŒ)")
            else:
                print(f"âŒ ê²°ê³¼: ì‹¤íŒ¨... (ì •ìƒ ë¬¸ì¥ì„ ë” ì„ í˜¸í•¨, ì°¨ì´: {diff:.4f})")
            
            print(f"ğŸ¤– ëª¨ë¸ ì˜ˆì¸¡: {'Anomalous' if pred==1 else 'Normal'} (ì •ë‹µ: Anomalous)")
            print("========================================================\n")
            anomaly_print_count += 1
            anomaly_diffs.append(diff)
        # ============ [ë””ë²„ê¹… ì½”ë“œ ë] ============
        
        gts.append(label)
        preds.append(pred)

    # 7. ë©”íŠ¸ë¦­ ê³„ì‚°
    gts = np.array(gts)
    preds = np.array(preds)

    tp = int(((preds==1)&(gts==1)).sum())
    fp = int(((preds==1)&(gts==0)).sum())
    tn = int(((preds==0)&(gts==0)).sum())
    fn = int(((preds==0)&(gts==1)).sum())

    precision = tp / max(1, (tp + fp))
    recall = tp / max(1, (tp + fn))
    f1 = 2 * precision * recall / max(1e-8, (precision + recall))
    acc = (tp + tn) / len(gts)

    print(f"Total: {len(gts)}")
    print(f"Accuracy: {acc:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1:.4f}")

    # ê²°ê³¼ ì €ì¥
    with open(os.path.join(args.output_dir, "results.txt"), "w") as f:
        f.write(f"Accuracy: {acc:.4f}\n")
        f.write(f"Precision: {precision:.4f}\n")
        f.write(f"Recall: {recall:.4f}\n")
        f.write(f"F1 Score: {f1:.4f}\n")
        f.write(f"TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}\n")
    
    norm_arr = np.array(normal_diffs)
    anom_arr = np.array(anomaly_diffs)

    print("\n======== [Calibration Result] ========")
    print(f"ğŸŸ¢ Normal Case Diffs (Mean): {norm_arr.mean():.4f} (Std: {norm_arr.std():.4f})")
    print(f"ğŸ”´ Anomaly Case Diffs (Mean): {anom_arr.mean():.4f} (Std: {anom_arr.std():.4f})")
    
    # 0ì„ ê¸°ì¤€ìœ¼ë¡œ í–ˆì„ ë•Œì˜ ì •í™•ë„
    # (ì›ë˜ ë¡œì§: diff > 0 ì´ë©´ Normal ì˜ˆì¸¡)
    acc_naive_norm = (norm_arr > 0).sum() / len(norm_arr) if len(norm_arr) > 0 else 0
    acc_naive_anom = (anom_arr <= 0).sum() / len(anom_arr) if len(anom_arr) > 0 else 0
    print(f"ğŸ“‰ ê¸°ì¤€ì  0.0 ì¼ ë•Œ Accuracy -> Normal: {acc_naive_norm*100:.1f}%, Anomaly: {acc_naive_anom*100:.1f}%")

    # ğŸ’¡ ìµœì  Threshold ì°¾ê¸° (ê°„ë‹¨í•œ ë²„ì „: ë‘ í‰ê· ì˜ ì¤‘ê°„ê°’)
    # ì •êµí•˜ê²Œ í•˜ë ¤ë©´ ROC Curveë¥¼ ê·¸ë ¤ì„œ Youden Indexë¥¼ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ë‘ ë¶„í¬ê°€ ê²¹ì¹˜ëŠ” êµ¬ê°„ì„ ë´…ë‹ˆë‹¤.
    
    if len(norm_arr) > 0 and len(anom_arr) > 0:
        # ëª¨ë¸ì´ í¸í–¥ë˜ì–´ì„œ Normal í‰ê· ì´ ìŒìˆ˜(-0.5)ë¼ë©´, ê¸°ì¤€ì ì„ -0.5 ê·¼ì²˜ë¡œ ì˜®ê²¨ì•¼ í•©ë‹ˆë‹¤.
        optimal_threshold = (norm_arr.mean() + anom_arr.mean()) / 2
        print(f"âš–ï¸ ì¶”ì²œ ìµœì  Threshold: {optimal_threshold:.4f}")
        
        # ë³´ì •ëœ Thresholdë¡œ ë‹¤ì‹œ ê³„ì‚°
        acc_calib_norm = (norm_arr > optimal_threshold).sum() / len(norm_arr)
        acc_calib_anom = (anom_arr <= optimal_threshold).sum() / len(anom_arr)
        print(f"ğŸ“ˆ ë³´ì • í›„ ì˜ˆìƒ Accuracy -> Normal: {acc_calib_norm*100:.1f}%, Anomaly: {acc_calib_anom*100:.1f}%")
        
        # F1 Score ì¬ê³„ì‚° (TP, FP, TN, FN)
        # Thresholdë³´ë‹¤ í¬ë©´ Normal(0), ì‘ìœ¼ë©´ Anomaly(1)
        TP = (anom_arr <= optimal_threshold).sum()
        FN = (anom_arr > optimal_threshold).sum()
        TN = (norm_arr > optimal_threshold).sum()
        FP = (norm_arr <= optimal_threshold).sum()
        
        precision = TP / (TP + FP + 1e-8)
        recall = TP / (TP + FN + 1e-8)
        f1 = 2 * precision * recall / (precision + recall + 1e-8)
        
        print(f"ğŸ† Final Calibrated F1 Score: {f1:.4f}")
    else:
        print("ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ Thresholdë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    print("\n" + "="*40)
    print(f"{'Category':<15} | {'AP':<10} | {'AUROC':<10}")
    print("-" * 40)
    
    ap_list = []
    auroc_list = []
    
    for cat, data in category_results.items():
        # ë°ì´í„° ë¶„ë¦¬
        y_true = [x[0] for x in data]      # ì •ë‹µ (0:ì •ìƒ, 1:ë¶ˆëŸ‰)
        y_scores = [x[1] for x in data]    # ì˜ˆì¸¡ ì ìˆ˜
        
        # ë°ì´í„°ê°€ ì„ì—¬ ìˆì–´ì•¼(ì •ìƒ/ë¶ˆëŸ‰ ë‘˜ ë‹¤ ì¡´ì¬) ê³„ì‚° ê°€ëŠ¥
        if len(set(y_true)) < 2:
            print(f"{cat:<15} | {'N/A':<10} | {'N/A':<10} (Only one class present)")
            continue
            
        # AP (Average Precision) ê³„ì‚°
        ap = average_precision_score(y_true, y_scores)
        
        # AUROC (Area Under ROC) ê³„ì‚° - ë¤ìœ¼ë¡œ ê°™ì´ ë´…ë‹ˆë‹¤
        auroc = roc_auc_score(y_true, y_scores)
        
        ap_list.append(ap)
        auroc_list.append(auroc)
        
        print(f"{cat:<15} | {ap:.4f}     | {auroc:.4f}")

    print("-" * 40)
    
    # mAP (APë“¤ì˜ í‰ê· )
    if len(ap_list) > 0:
        mAP = sum(ap_list) / len(ap_list)
        mAUROC = sum(auroc_list) / len(auroc_list)
        print(f"ğŸ¥‡ mAP (Mean Average Precision): {mAP:.4f}")
        print(f"ğŸ¥ˆ mAUROC (Mean AUROC)       : {mAUROC:.4f}")
        
        # íŒŒì¼ ì €ì¥
        with open(os.path.join(args.output_dir, "map_results.txt"), "w") as f:
            f.write(f"mAP: {mAP:.4f}\n")
            f.write(f"mAUROC: {mAUROC:.4f}\n")
    else:
        print("ê³„ì‚° ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

    print("\n======== [Finding Optimal F1 Score] ========")
    from sklearn.metrics import precision_recall_curve

    all_labels = []
    all_scores = []

    # ëª¨ë“  ì¹´í…Œê³ ë¦¬ì˜ ë°ì´í„°ë¥¼ í•œê³³ì— ëª¨ìë‹ˆë‹¤.
    for cat, data in category_results.items():
        for label, score in data:
            all_labels.append(label)
            all_scores.append(score)

    all_labels = np.array(all_labels)
    all_scores = np.array(all_scores)

    # Precision-Recall Curveë¥¼ ê·¸ë ¤ì„œ ìµœê³ ì˜ F1 ì§€ì ì„ ì°¾ìŠµë‹ˆë‹¤.
    precision, recall, thresholds = precision_recall_curve(all_labels, all_scores)
    
    # F1 ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
    numerator = 2 * precision * recall
    denominator = precision + recall
    f1_scores = np.divide(numerator, denominator, out=np.zeros_like(numerator), where=denominator != 0)
    
    # ìµœëŒ€ F1 Scoreì™€ ê·¸ë•Œì˜ Threshold ì°¾ê¸°
    best_idx = np.argmax(f1_scores)
    best_f1 = f1_scores[best_idx]
    best_threshold = thresholds[best_idx]

    print(f"ğŸ’ Best Possible F1 Score: {best_f1:.4f}")
    print(f"âš–ï¸ Optimal Threshold: {best_threshold:.4f}")
    print("--------------------------------------------")
    print("ì´ ê°’ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì˜ˆì¸¡ì„ í•˜ë©´ ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤.")

    print("\n" + "="*50)
    print("ğŸ’ Calculating Best F1 Score per Category")
    print("="*50)
    
    f1_list = []
    
    print(f"{'Category':<15} | {'Best F1':<10} | {'Threshold':<10}")
    print("-" * 50)

    # 1. ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë”°ë¡œë”°ë¡œ ìµœì ì˜ F1ì„ êµ¬í•©ë‹ˆë‹¤.
    for cat, data in category_results.items():
        y_true = np.array([x[0] for x in data])
        y_scores = np.array([x[1] for x in data])

        # ì •ìƒ ë˜ëŠ” ë¶ˆëŸ‰ ë°ì´í„°ë§Œ ìˆëŠ” ê²½ìš° ê³„ì‚° ë¶ˆê°€
        if len(set(y_true)) < 2:
            print(f"{cat:<15} | {'N/A':<10} | {'N/A':<10} (Skipped)")
            continue

        # Precision-Recall Curve ê³„ì‚°
        precision, recall, thresholds = precision_recall_curve(y_true, y_scores)
        
        # F1 Score ê³„ì‚°
        numerator = 2 * precision * recall
        denominator = precision + recall
        f1_scores = np.divide(numerator, denominator, out=np.zeros_like(numerator), where=denominator != 0)
        
        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œì˜ ìµœê³  ì ìˆ˜ ì°¾ê¸°
        best_idx = np.argmax(f1_scores)
        best_f1 = f1_scores[best_idx]
        best_threshold = thresholds[best_idx] if best_idx < len(thresholds) else thresholds[-1]
        
        f1_list.append(best_f1)
        
        print(f"{cat:<15} | {best_f1:.4f}     | {best_threshold:.4f}")

    print("-" * 50)

    # 2. ìµœì¢… ì ìˆ˜: ì¹´í…Œê³ ë¦¬ë³„ F1ì˜ í‰ê·  (Macro Average)
    if len(f1_list) > 0:
        macro_f1 = sum(f1_list) / len(f1_list)
        print(f"ğŸ† Class-Average Best F1 Score: {macro_f1:.4f}")
        
        with open(os.path.join(args.output_dir, "class_wise_f1.txt"), "w") as f:
            f.write(f"Class-Average Best F1: {macro_f1:.4f}\n")
    else:
        print("ê³„ì‚°ëœ F1 ì ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()